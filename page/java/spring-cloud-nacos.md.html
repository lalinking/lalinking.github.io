<!DOCTYPE html>
<html lang="zh">
<head>
	<meta charset="UTF-8">
	<meta name="keywords" content="java,spring cloud,nacos">
	<meta name="description" content="spring cloud nacos 学习笔记">
	<meta name="author" content="lalinking">
	<meta name="copyright" content="lalinking">
	<link href="/resource/upgrade.css" type="text/css" rel="stylesheet">
	<link href="/resource/v2/main.css" type="text/css" rel="stylesheet">
	<link href="/resource/v2/md.css" type="text/css" rel="stylesheet">
	<link href="/3rd-lib/gitalk/gitalk.css" type="text/css" rel="stylesheet">
	<link href="/3rd-lib/prism/prism.css" type="text/css" rel="stylesheet">
	<title>打工姿态 -> 学习姿态</title>
</head>
<body>
<noscript>[TOC]

# Nacos 简介
nacos 是阿里集团开源的微服务组件。
它的功能列表即实现情况见 [官网链接]: https://nacos.io/zh-cn/docs/feature-list.html 。 主要功能是服务发现与配置管理。
nacos 下载地址 [github release]: https://github.com/alibaba/nacos/releases 。
nacos 配置说明：[官网链接]: https://nacos.io/zh-cn/docs/system-configurations.html 。

## 功能模块说明
1. Naming模块：服务注册与发现、健康检查（服务端探测、客户端心跳）、路由策略（权重、保护阈值、就近访问）。就近访问即配置中 CMDB Module 这一块的内容。
2. Config模块：配置管理（发布、修改、查询、监听配置）、灰度配置。不支持加密配置。支持存储在 mysql 数据库中。
3. Nacos-Sync：Nacos与Nacos服务双向同步、Nacos与Zookeeper服务双向同步、Nacos与Eureka服务双向同步、Nacos与Consul服务双向同步。

## Nacos 部署
为了方便，采用 docker 容器部署。依赖的 mysql 使用已存在的服务。
关于 docker 部署 nacos 的官方文档：https://github.com/nacos-group/nacos-docker/blob/master/README_ZH.md 。
官方镜像不方便修改 nacos 版本以及各种自定义，因此自行定制 docker 镜像。

### 自定义 Nacos Docker 镜像
dockerFile：

```
# FROM 表示基于这个镜像进行创建，下面这个镜像是适用于 jar 的最小镜像
FROM openjdk:8-jre-slim

# 指定工作路径
WORKDIR /tmp

# 把启动脚本放进容器
COPY ./boot.sh /usr/boot.sh

# 构建镜像时运行以下脚本，授予权限
RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && \
 chmod +x /usr/boot.sh

# 声明守护端口
EXPOSE 8080
 
# docker 容器启动时运行的命令，这个脚本会将指定路径（含子路径）的 jar 包全部启动
# 遇到一个问题，docker 的机制 0 号进程退出会导致整个容器终端，因此加一个 tail -f 防止退出
CMD bash /usr/boot.sh

# 打标签
LABEL org.opencontainers.image.authors="lalinking"
```

其中 boot.sh 内容如下

```bash
#!/bin/bash

echo "================================================================================="
echo "boot start."
date

startup_file="/usr/java/workpath/on_boot.sh"
if [ ! -f $startup_file ]; then
  echo "$startup_file not exists. do initial."
  echo "#!/bin/bash"                                                     > $startup_file
  echo "set -e"                                                         >> $startup_file
  echo ""                                                               >> $startup_file
  echo "# 执行jar"                                                      >> $startup_file
  echo "#  如果路径下有 jvm.args 文件，则读取里面的参数"                >> $startup_file
  echo "#  如果没有 jvm.args 文件，则使用默认参数： -server"            >> $startup_file
  echo "runjar()"                                                       >> $startup_file
  echo "{"                                                              >> $startup_file
  echo "    run_file=\$1"                                               >> $startup_file
  echo "    run_path=\$(dirname \$run_file)"                            >> $startup_file
  echo "    jvmArgs=\"-server\""                                        >> $startup_file
  echo "    if [ -f \"\$run_path/jvm.args\" ]; then"                    >> $startup_file
  echo "        jvmArgs=\$(head -n 1 \$run_path/jvm.args)"              >> $startup_file
  echo "    fi"                                                         >> $startup_file
  echo "    echo \"run: \$1, args: \$jvmArgs\""                         >> $startup_file
  echo "	# 这里必须先 cd 到路径，不然 springboot 读取配置文件有问题" >> $startup_file
  echo "    cd /usr/java/workpath/"                                     >> $startup_file
  echo "    cd \$run_path"                                              >> $startup_file
  echo "    java \$jvmArgs -jar \$run_file >> \$run_path/vmlog 2>&1 &"  >> $startup_file
  echo "}"                                                              >> $startup_file
  echo ""                                                               >> $startup_file
  echo "cd /usr/java/workpath/"                                         >> $startup_file
  echo ""                                                               >> $startup_file
  echo "# 示例"                                                         >> $startup_file
  echo "# runjar \"/usr/java/workpath/sample.jar\""                     >> $startup_file
  echo ""                                                               >> $startup_file
  echo "# 保持容器不退出（放到最后一行）"                               >> $startup_file
  echo "tail -n 0 -f \$0"                                               >> $startup_file
  echo "empty command, exit"
  exit 0
fi

# 授予执行权限
if [ ! -x $startup_file ]; then
  echo "give +x to $startup_file"
  chmod +x $startup_file
fi

sh $startup_file
```

构建镜像
```bash
docker build -f .\Dockerfile -t jar_runner:open-jre8 .
```

### 下载 Nacos
下载地址： [github release]: https://github.com/alibaba/nacos/releases
选择最新版，目前是 2.0.3。下载得到的是一个压缩包，解压后放到 D:\docker\volume\regist_center\nacos
注意文件目录结构：
    D:\docker\volume\regist_center\nacos
    D:\docker\volume\regist_center\nacos\bin
    D:\docker\volume\regist_center\nacos\conf
    D:\docker\volume\regist_center\nacos\target
后续将 D:\docker\volume\regist_center 映射为容器内的 /usr/java/workpath/ 路径。
修改配置文件 conf/application.properties （基本上没改动，参数的作用参考注释，或上面给出的链接）

```
#
# Copyright 1999-2021 Alibaba Group Holding Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#*************** Spring Boot Related Configurations ***************#
### Default web context path:
server.servlet.contextPath=/nacos
### Default web server port:
server.port=8080

#*************** Network Related Configurations ***************#
### If prefer hostname over ip for Nacos server addresses in cluster.conf:
# nacos.inetutils.prefer-hostname-over-ip=false

### Specify local server's IP:
# nacos.inetutils.ip-address=


#*************** Config Module Related Configurations ***************#
### If use MySQL as datasource:
# spring.datasource.platform=mysql

### Count of DB:
# db.num=1

### Connect URL of DB:
# db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
# db.user.0=nacos
# db.password.0=nacos

### Connection pool configuration: hikariCP
db.pool.config.connectionTimeout=30000
db.pool.config.validationTimeout=10000
db.pool.config.maximumPoolSize=20
db.pool.config.minimumIdle=2

#*************** Naming Module Related Configurations ***************#

### If enable data warmup. If set to false, the server would accept request without local data preparation:
nacos.naming.data.warmup=true

### If enable the instance auto expiration, kind like of health check of instance:
# 临时实例的概念暂不清楚
nacos.naming.expireInstance=true

### Add in 2.0.0
### The interval to clean empty service, unit: milliseconds.
nacos.naming.clean.empty-service.interval=60000

### The expired time to clean empty service, unit: milliseconds.
nacos.naming.clean.empty-service.expired-time=60000

### The interval to clean expired metadata, unit: milliseconds.
nacos.naming.clean.expired-metadata.interval=5000

### The expired time to clean metadata, unit: milliseconds.
nacos.naming.clean.expired-metadata.expired-time=60000

### The delay time before push task to execute from service changed, unit: milliseconds.
nacos.naming.push.pushTaskDelay=500

### The timeout for push task execute, unit: milliseconds.
nacos.naming.push.pushTaskTimeout=5000

### The delay time for retrying failed push task, unit: milliseconds.
nacos.naming.push.pushTaskRetryDelay=1000

### Since 2.0.3
### The expired time for inactive client, unit: milliseconds.
nacos.naming.client.expired.time=180000

#*************** CMDB Module Related Configurations ***************#
### The interval to dump external CMDB in seconds:
nacos.cmdb.dumpTaskInterval=3600

### The interval of polling data change event in seconds:
nacos.cmdb.eventTaskInterval=10

### The interval of loading labels in seconds:
nacos.cmdb.labelTaskInterval=300

### If turn on data loading task:
nacos.cmdb.loadDataAtStart=false


#*************** Metrics Related Configurations ***************#
### Metrics for prometheus
#management.endpoints.web.exposure.include=*

### Metrics for elastic search
management.metrics.export.elastic.enabled=false
#management.metrics.export.elastic.host=http://localhost:9200

### Metrics for influx
management.metrics.export.influx.enabled=false
#management.metrics.export.influx.db=springboot
#management.metrics.export.influx.uri=http://localhost:8086
#management.metrics.export.influx.auto-create-db=true
#management.metrics.export.influx.consistency=one
#management.metrics.export.influx.compressed=true

#*************** Access Log Related Configurations ***************#
### If turn on the access log:
server.tomcat.accesslog.enabled=true

### The access log pattern:
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i %{Request-Source}i

### The directory of access log:
server.tomcat.basedir=

#*************** Access Control Related Configurations ***************#
### If enable spring security, this option is deprecated in 1.2.0:
#spring.security.enabled=false

### The ignore urls of auth, is deprecated in 1.2.0:
nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**

### The auth system to use, currently only 'nacos' and 'ldap' is supported:
nacos.core.auth.system.type=nacos

### If turn on auth system:
nacos.core.auth.enabled=false

### worked when nacos.core.auth.system.type=ldap，{0} is Placeholder,replace login username
# nacos.core.auth.ldap.url=ldap://localhost:389
# nacos.core.auth.ldap.userdn=cn={0},ou=user,dc=company,dc=com

### The token expiration in seconds:
nacos.core.auth.default.token.expire.seconds=18000

### The default token:
nacos.core.auth.default.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789

### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.
nacos.core.auth.caching.enabled=true

### Since 1.4.1, Turn on/off white auth for user-agent: nacos-server, only for upgrade from old version.
nacos.core.auth.enable.userAgentAuthWhite=false

### Since 1.4.1, worked when nacos.core.auth.enabled=true and nacos.core.auth.enable.userAgentAuthWhite=false.
### The two properties is the white list for auth and used by identity the request from other server.
nacos.core.auth.server.identity.key=serverIdentity
nacos.core.auth.server.identity.value=security

#*************** Istio Related Configurations ***************#
### If turn on the MCP server:
nacos.istio.mcp.server.enabled=false

#*************** Core Related Configurations ***************#

### set the WorkerID manually
# nacos.core.snowflake.worker-id=

### Member-MetaData
# nacos.core.member.meta.site=
# nacos.core.member.meta.adweight=
# nacos.core.member.meta.weight=

### MemberLookup
### Addressing pattern category, If set, the priority is highest
# nacos.core.member.lookup.type=[file,address-server]
## Set the cluster list with a configuration file or command-line argument
# nacos.member.list=192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809
## for AddressServerMemberLookup
# Maximum number of retries to query the address server upon initialization
# nacos.core.address-server.retry=5
## Server domain name address of [address-server] mode
# address.server.domain=jmenv.tbsite.net
## Server port of [address-server] mode
# address.server.port=8080
## Request address of [address-server] mode
# address.server.url=/nacos/serverlist

#*************** JRaft Related Configurations ***************#

### Sets the Raft cluster election timeout, default value is 5 second
# nacos.core.protocol.raft.data.election_timeout_ms=5000
### Sets the amount of time the Raft snapshot will execute periodically, default is 30 minute
# nacos.core.protocol.raft.data.snapshot_interval_secs=30
### raft internal worker threads
# nacos.core.protocol.raft.data.core_thread_num=8
### Number of threads required for raft business request processing
# nacos.core.protocol.raft.data.cli_service_thread_num=4
### raft linear read strategy. Safe linear reads are used by default, that is, the Leader tenure is confirmed by heartbeat
# nacos.core.protocol.raft.data.read_index_type=ReadOnlySafe
### rpc request timeout, default 5 seconds
# nacos.core.protocol.raft.data.rpc_request_timeout_ms=5000

#*************** Distro Related Configurations ***************#

### Distro data sync delay time, when sync task delayed, task will be merged for same data key. Default 1 second.
# nacos.core.protocol.distro.data.sync.delayMs=1000

### Distro data sync timeout for one sync data, default 3 seconds.
# nacos.core.protocol.distro.data.sync.timeoutMs=3000

### Distro data sync retry delay time when sync data failed or timeout, same behavior with delayMs, default 3 seconds.
# nacos.core.protocol.distro.data.sync.retryDelayMs=3000

### Distro data verify interval time, verify synced data whether expired for a interval. Default 5 seconds.
# nacos.core.protocol.distro.data.verify.intervalMs=5000

### Distro data verify timeout for one verify, default 3 seconds.
# nacos.core.protocol.distro.data.verify.timeoutMs=3000

### Distro data load retry delay when load snapshot data failed, default 30 seconds.
# nacos.core.protocol.distro.data.load.retryDelayMs=30000
```

### 启动 Docker 容器

映射端口和路径，启动容器（我的是 win10 路径）

```bash
docker run -p 8001:8080 -v D:\docker\volume\regist_center\:/usr/java/workpath --name register_center -d jar_runner:open-jre8
```

用上面命令创建容器后会生成 D:\docker\volume\regist_center\on_boot.sh 这个文件后退出，加入一行启动 nacos 的命令：

```bash
# 如果是集群部署，去掉后面的 -m standalone
# 先 cd 到 nacos，不然会在 /usr/java/workpath 这一层就生成 tomcat 的日志文件
cd /usr/java/workpath/nacos/ && bash ./bin/startup.sh -m standalone
```

然后再启动容器，会看到生成了 logs 文件夹，查看一下 nacos/logs/start.out，看有没有报错。
第一次启动会生成各种文件，所需要的时间比较久。没有报错的话可以打开浏览器访问控制台 http://localhost:8001/nacos 用户名和密码都是 nacos

### 服务注册客户端


</noscript>
<div id="header">好好学习  天天向上</div>
<div id="main">
	<div id="bord">
		<div id="eraser" title="擦除" data-click="clear"></div><div id="sp_top"></div><div id="left"><div id="left_content"></div></div><div id="sp_bottom"></div>
		<div id="center"><div id="center_content"></div></div>
		<div id="tips"><div id="tips_content"><p>这节课老师<small>不</small>点名</p><p>但学习是为了自己！</p></div></div>
	</div>
</div>
<div id="foot">
	<div id="talk"></div>
</div>
</body>
<script src="/resource/upgrade.js"></script>
<script src="/resource/v2/pageInit.js"></script>
<script>
	// 初始化索引
	var bookInfos = JSON.parse('{"maxThickness":1,"maxHeight":1,"M-154268230":{"BookId":"M-154268230","BookName":"Java 笔记","contents":[{"FileTitle":"RestTemplate 日志打印请求和返回内容","BookName":"Java 笔记","Date":"2022-04-14","Description":"RestTemplate 日志打印请求和返回内容","Keywords":"java,SpringBoot,RestTemplate","FilePath":"java/RestTemplateConfig.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/RestTemplateConfig.md","Content":"## 功能\n\nRestTemplate 发起请求前，打印请求消息体；收到应答时，打印返回内容。并且不影响后续程序的读取和解析。\n某些请求不打印日志，避免泄露机密信息。\n这里认为 RestTemplate 只用来做 http api 交互，即请求体和响应体都是文本。\n\n## 使用\n\nSpringBoot 注入配置 Bean 即可。\n\n## 原理\n\nRestTemplate 有拦截器机制，利用拦截器机制可打印请求的发送和应答内容。\n其中应答内容需要从流中读取，但这样会影响后续代码的读取和解析（流读取过一次以后就没了）。因此对响应流进行封装，重写读取方法，这样在流真正被读取内容时同步得获取到响应内容。\n\n## 源码\n\n```java\n    @Bean\n    public RestTemplate getRestTemplate() {\n        final RestTemplate restTemplate = new RestTemplate();\n        // 设置一个拦截器打印前后请求日志\n        restTemplate.setInterceptors(Collections.singletonList((request, body, execution) -> {\n            // 内部的一个标志，这样的请求不要打印内容，否则泄露密码\n            boolean trace = !\"NO\".equals(request.getHeaders().getFirst(\"Trace\"));\n            log.info(\"Rest Start\\n  Url: {}\\n  Body: {}\", request.getURI().toURL(), trace ? new String(body, StandardCharsets.UTF_8) : \"****\");\n            final long before = System.currentTimeMillis();\n            ClientHttpResponse response = execution.execute(request, body);\n            if (!trace) {\n                log.info(\"Rest Done\\n  Use time: {}\\n  Response: ****\", System.currentTimeMillis() - before);\n                return response;\n            }\n            // 封装一个对象，以便能在不影响后续处理的情况下打印返回结果\n            return new ClientHttpResponse() {\n                final ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n\n                @Override\n                public HttpHeaders getHeaders() {\n                    return response.getHeaders();\n                }\n\n                @Override\n                public InputStream getBody() throws IOException {\n                    // 封装一个流，监听读取事件\n                    final InputStream bodyInputStream = response.getBody();\n                    return new InputStream() {\n                        @Override\n                        public int read() throws IOException {\n                            final int read = bodyInputStream.read();\n                            if (read != -1) {\n                                outputStream.write(read);\n                            }\n                            return read;\n                        }\n\n                        @Override\n                        public long skip(long n) throws IOException {\n                            return bodyInputStream.skip(n);\n                        }\n\n                        @Override\n                        public int available() throws IOException {\n                            return bodyInputStream.available();\n                        }\n\n                        @Override\n                        public void close() throws IOException {\n                            bodyInputStream.close();\n                            outputStream.close();\n                            // 文件读取结束了，打印读到的内容\n                            log.info(\"Rest Done\\n  Use time: {}\\n  Response: {}\", System.currentTimeMillis() - before, outputStream.toString(\"utf-8\"));\n                        }\n\n                        @Override\n                        public synchronized void mark(int readlimit) {\n                            bodyInputStream.mark(readlimit);\n                        }\n\n                        @Override\n                        public synchronized void reset() throws IOException {\n                            bodyInputStream.reset();\n                        }\n\n                        @Override\n                        public boolean markSupported() {\n                            return bodyInputStream.markSupported();\n                        }\n                    };\n                }\n\n                @Override\n                public HttpStatus getStatusCode() throws IOException {\n                    return response.getStatusCode();\n                }\n\n                @Override\n                public int getRawStatusCode() throws IOException {\n                    return response.getRawStatusCode();\n                }\n\n                @Override\n                public String getStatusText() throws IOException {\n                    return response.getStatusText();\n                }\n\n                @Override\n                public void close() {\n                    response.close();\n                }\n            };\n        }));\n        return restTemplate;\n    }\n```\n","BookId":"M-154268230","CompileTime":"2022-04-15T10:39:49.730Z"},{"FileTitle":"bash 脚本实现按关键字搜索日志，并按线程号分组显示且支持高亮","BookName":"Java 笔记","Date":"2021-11-17","Description":"Linux 服务器下利用 grep+awk 实现按关键字搜索日志，并按线程号分组显示且支持高亮","Keywords":"bash,日志,java","FilePath":"java/GrepJavaLog.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/GrepJavaLog.md","Content":"Linux 服务器下利用 grep+awk 实现按关键字搜索日志，并按线程号分组显示且支持高亮。\n注日期格式：\n\n```\n18:48:51.143 [http-nio-8081-exec-273] INFO  com.c.m.p.ChangeProducer:44 - 输出的日志\n```\n\n// TODO\n如果输出的日志存在换行，因找不到线程号，所以换行的内容不能被搜索到。\n异常日志都有换行，所以异常日志都搜索不到。\n\n```bash\n#!/bin/bash\n\n# 找出所有日志文件\npathlist=(`find /release_sw/$1/logs/ -name \"*.log\" |xargs ls -1t |grep ^/` )\necho \"已找到如下文件，输入文件序号\"\n\n# 搜索的关键字，后面可以重新输入\nsearchstr=$3\n# 搜索的范围\nshowlines=$2\nif [ ! \"$showlines\" ]; then\n\tshowlines=50\n\techo \"$showlines\"\nfi\n\n# 从文件搜索、打印结果的函数\nsearchfile()\n{\n\techo \"扫描：$1\"\n\tread -p \"输入 搜索的字符串（当前为 $searchstr）: \" newsearchstr\n\tif [ \"$newsearchstr\" ]; then\n\t\tsearchstr=\"$newsearchstr\"\n\tfi\n\t\n\techo \"搜索：$searchstr\"\n\t# 搜索得到行号\n\tgreplist=(`fgrep --color=never -n \"$searchstr\" $1 | egrep --color=never -e \"^[0-9]+\" -o`)\n\tfor(( i=0; i<${#greplist[@]}; i++ ))\n\tdo\n\t\t# 获取前后若干行的内容\n\t\tstartline=$((${greplist[$i]}-$showlines))\n\t\tendline=$((${greplist[$i]}+$showlines))\n\t\techo -e \"\\n\\n搜索行数范围： $startline ~ $endline；$(($i/2)) / $((${#greplist[@]}/2))\"\n\t\t# 获取线程号，从这一行开始，向上遍历取到第一个\n\t\t# 将这些行的内容按线程号过滤，打印出来\n\t\tawk \"NR>${startline} && NR<${endline}\" $1 | fgrep -C $showlines --color=always \"$searchstr\"\n\t\t#awk \"NR>${startline} && NR<${endline}\" $1 | fgrep --color=always -F \"${greplist[$i+1]}\" | fgrep -C $showlines --color=always \"$searchstr\"\n\tdone\n}\n\n# 主函数，一直询问选择哪个文件进行搜索\ndoask()\n{\n\tfor(( i=1; i<=${#pathlist[@]}; i++ ))\n\tdo\n\t\techo $i: ${pathlist[$i-1]}\n\tdone\n\n\tread -p \"输入需要扫描的文件序号（0 退出）: \" pathindex\n\tif [ ! $pathindex ]; then\n\t\techo \"Bye\"\n\t\texit 0\n\tfi\n\tif [ $pathindex -lt \"1\" ]; then\n\t\techo \"Bye\"\n\t\texit 0\n\tfi\n\tpath=${pathlist[$pathindex-1]}\n\tif [ $path ]; then\n\t\tsearchfile \"$path\"\n\telse\n\t\techo \"无效输入\"\n\tfi\n\tread -p \"继续搜索？（回车继续，其他则退出）: \" continues\n\tif [ $continues ]; then\n\t\techo \"Bye\"\n\t\texit 0\n\tfi\n\tdoask\n}\n\nif [ ${#pathlist[@]} > 1 ]; then\n\tdoask\nelse\n\tsearchfile \"${pathlist[0]}\"\nfi\n```","BookId":"M-154268230","CompileTime":"2022-04-15T10:39:49.827Z"},{"FileTitle":"Spring-Cloud nacos 学习笔记","BookName":"Java 笔记","Date":"2021-11-10","Description":"spring cloud nacos 学习笔记","Keywords":"java,spring cloud,nacos","FilePath":"java/spring-cloud-nacos.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/spring-cloud-nacos.md","Content":"[TOC]\n\n# Nacos 简介\nnacos 是阿里集团开源的微服务组件。\n它的功能列表即实现情况见 [官网链接]: https://nacos.io/zh-cn/docs/feature-list.html 。 主要功能是服务发现与配置管理。\nnacos 下载地址 [github release]: https://github.com/alibaba/nacos/releases 。\nnacos 配置说明：[官网链接]: https://nacos.io/zh-cn/docs/system-configurations.html 。\n\n## 功能模块说明\n1. Naming模块：服务注册与发现、健康检查（服务端探测、客户端心跳）、路由策略（权重、保护阈值、就近访问）。就近访问即配置中 CMDB Module 这一块的内容。\n2. Config模块：配置管理（发布、修改、查询、监听配置）、灰度配置。不支持加密配置。支持存储在 mysql 数据库中。\n3. Nacos-Sync：Nacos与Nacos服务双向同步、Nacos与Zookeeper服务双向同步、Nacos与Eureka服务双向同步、Nacos与Consul服务双向同步。\n\n## Nacos 部署\n为了方便，采用 docker 容器部署。依赖的 mysql 使用已存在的服务。\n关于 docker 部署 nacos 的官方文档：https://github.com/nacos-group/nacos-docker/blob/master/README_ZH.md 。\n官方镜像不方便修改 nacos 版本以及各种自定义，因此自行定制 docker 镜像。\n\n### 自定义 Nacos Docker 镜像\ndockerFile：\n\n```\n# FROM 表示基于这个镜像进行创建，下面这个镜像是适用于 jar 的最小镜像\nFROM openjdk:8-jre-slim\n\n# 指定工作路径\nWORKDIR /tmp\n\n# 把启动脚本放进容器\nCOPY ./boot.sh /usr/boot.sh\n\n# 构建镜像时运行以下脚本，授予权限\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && \\\n chmod +x /usr/boot.sh\n\n# 声明守护端口\nEXPOSE 8080\n \n# docker 容器启动时运行的命令，这个脚本会将指定路径（含子路径）的 jar 包全部启动\n# 遇到一个问题，docker 的机制 0 号进程退出会导致整个容器终端，因此加一个 tail -f 防止退出\nCMD bash /usr/boot.sh\n\n# 打标签\nLABEL org.opencontainers.image.authors=\"lalinking\"\n```\n\n其中 boot.sh 内容如下\n\n```bash\n#!/bin/bash\n\necho \"=================================================================================\"\necho \"boot start.\"\ndate\n\nstartup_file=\"/usr/java/workpath/on_boot.sh\"\nif [ ! -f $startup_file ]; then\n  echo \"$startup_file not exists. do initial.\"\n  echo \"#!/bin/bash\"                                                     > $startup_file\n  echo \"set -e\"                                                         >> $startup_file\n  echo \"\"                                                               >> $startup_file\n  echo \"# 执行jar\"                                                      >> $startup_file\n  echo \"#  如果路径下有 jvm.args 文件，则读取里面的参数\"                >> $startup_file\n  echo \"#  如果没有 jvm.args 文件，则使用默认参数： -server\"            >> $startup_file\n  echo \"runjar()\"                                                       >> $startup_file\n  echo \"{\"                                                              >> $startup_file\n  echo \"    run_file=\\$1\"                                               >> $startup_file\n  echo \"    run_path=\\$(dirname \\$run_file)\"                            >> $startup_file\n  echo \"    jvmArgs=\\\"-server\\\"\"                                        >> $startup_file\n  echo \"    if [ -f \\\"\\$run_path/jvm.args\\\" ]; then\"                    >> $startup_file\n  echo \"        jvmArgs=\\$(head -n 1 \\$run_path/jvm.args)\"              >> $startup_file\n  echo \"    fi\"                                                         >> $startup_file\n  echo \"    echo \\\"run: \\$1, args: \\$jvmArgs\\\"\"                         >> $startup_file\n  echo \"\t# 这里必须先 cd 到路径，不然 springboot 读取配置文件有问题\" >> $startup_file\n  echo \"    cd /usr/java/workpath/\"                                     >> $startup_file\n  echo \"    cd \\$run_path\"                                              >> $startup_file\n  echo \"    java \\$jvmArgs -jar \\$run_file >> \\$run_path/vmlog 2>&1 &\"  >> $startup_file\n  echo \"}\"                                                              >> $startup_file\n  echo \"\"                                                               >> $startup_file\n  echo \"cd /usr/java/workpath/\"                                         >> $startup_file\n  echo \"\"                                                               >> $startup_file\n  echo \"# 示例\"                                                         >> $startup_file\n  echo \"# runjar \\\"/usr/java/workpath/sample.jar\\\"\"                     >> $startup_file\n  echo \"\"                                                               >> $startup_file\n  echo \"# 保持容器不退出（放到最后一行）\"                               >> $startup_file\n  echo \"tail -n 0 -f \\$0\"                                               >> $startup_file\n  echo \"empty command, exit\"\n  exit 0\nfi\n\n# 授予执行权限\nif [ ! -x $startup_file ]; then\n  echo \"give +x to $startup_file\"\n  chmod +x $startup_file\nfi\n\nsh $startup_file\n```\n\n构建镜像\n```bash\ndocker build -f .\\Dockerfile -t jar_runner:open-jre8 .\n```\n\n### 下载 Nacos\n下载地址： [github release]: https://github.com/alibaba/nacos/releases\n选择最新版，目前是 2.0.3。下载得到的是一个压缩包，解压后放到 D:\\docker\\volume\\regist_center\\nacos\n注意文件目录结构：\n    D:\\docker\\volume\\regist_center\\nacos\n    D:\\docker\\volume\\regist_center\\nacos\\bin\n    D:\\docker\\volume\\regist_center\\nacos\\conf\n    D:\\docker\\volume\\regist_center\\nacos\\target\n后续将 D:\\docker\\volume\\regist_center 映射为容器内的 /usr/java/workpath/ 路径。\n修改配置文件 conf/application.properties （基本上没改动，参数的作用参考注释，或上面给出的链接）\n\n```\n#\n# Copyright 1999-2021 Alibaba Group Holding Ltd.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n#*************** Spring Boot Related Configurations ***************#\n### Default web context path:\nserver.servlet.contextPath=/nacos\n### Default web server port:\nserver.port=8080\n\n#*************** Network Related Configurations ***************#\n### If prefer hostname over ip for Nacos server addresses in cluster.conf:\n# nacos.inetutils.prefer-hostname-over-ip=false\n\n### Specify local server's IP:\n# nacos.inetutils.ip-address=\n\n\n#*************** Config Module Related Configurations ***************#\n### If use MySQL as datasource:\n# spring.datasource.platform=mysql\n\n### Count of DB:\n# db.num=1\n\n### Connect URL of DB:\n# db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC\n# db.user.0=nacos\n# db.password.0=nacos\n\n### Connection pool configuration: hikariCP\ndb.pool.config.connectionTimeout=30000\ndb.pool.config.validationTimeout=10000\ndb.pool.config.maximumPoolSize=20\ndb.pool.config.minimumIdle=2\n\n#*************** Naming Module Related Configurations ***************#\n\n### If enable data warmup. If set to false, the server would accept request without local data preparation:\nnacos.naming.data.warmup=true\n\n### If enable the instance auto expiration, kind like of health check of instance:\n# 临时实例的概念暂不清楚\nnacos.naming.expireInstance=true\n\n### Add in 2.0.0\n### The interval to clean empty service, unit: milliseconds.\nnacos.naming.clean.empty-service.interval=60000\n\n### The expired time to clean empty service, unit: milliseconds.\nnacos.naming.clean.empty-service.expired-time=60000\n\n### The interval to clean expired metadata, unit: milliseconds.\nnacos.naming.clean.expired-metadata.interval=5000\n\n### The expired time to clean metadata, unit: milliseconds.\nnacos.naming.clean.expired-metadata.expired-time=60000\n\n### The delay time before push task to execute from service changed, unit: milliseconds.\nnacos.naming.push.pushTaskDelay=500\n\n### The timeout for push task execute, unit: milliseconds.\nnacos.naming.push.pushTaskTimeout=5000\n\n### The delay time for retrying failed push task, unit: milliseconds.\nnacos.naming.push.pushTaskRetryDelay=1000\n\n### Since 2.0.3\n### The expired time for inactive client, unit: milliseconds.\nnacos.naming.client.expired.time=180000\n\n#*************** CMDB Module Related Configurations ***************#\n### The interval to dump external CMDB in seconds:\nnacos.cmdb.dumpTaskInterval=3600\n\n### The interval of polling data change event in seconds:\nnacos.cmdb.eventTaskInterval=10\n\n### The interval of loading labels in seconds:\nnacos.cmdb.labelTaskInterval=300\n\n### If turn on data loading task:\nnacos.cmdb.loadDataAtStart=false\n\n\n#*************** Metrics Related Configurations ***************#\n### Metrics for prometheus\n#management.endpoints.web.exposure.include=*\n\n### Metrics for elastic search\nmanagement.metrics.export.elastic.enabled=false\n#management.metrics.export.elastic.host=http://localhost:9200\n\n### Metrics for influx\nmanagement.metrics.export.influx.enabled=false\n#management.metrics.export.influx.db=springboot\n#management.metrics.export.influx.uri=http://localhost:8086\n#management.metrics.export.influx.auto-create-db=true\n#management.metrics.export.influx.consistency=one\n#management.metrics.export.influx.compressed=true\n\n#*************** Access Log Related Configurations ***************#\n### If turn on the access log:\nserver.tomcat.accesslog.enabled=true\n\n### The access log pattern:\nserver.tomcat.accesslog.pattern=%h %l %u %t \"%r\" %s %b %D %{User-Agent}i %{Request-Source}i\n\n### The directory of access log:\nserver.tomcat.basedir=\n\n#*************** Access Control Related Configurations ***************#\n### If enable spring security, this option is deprecated in 1.2.0:\n#spring.security.enabled=false\n\n### The ignore urls of auth, is deprecated in 1.2.0:\nnacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**\n\n### The auth system to use, currently only 'nacos' and 'ldap' is supported:\nnacos.core.auth.system.type=nacos\n\n### If turn on auth system:\nnacos.core.auth.enabled=false\n\n### worked when nacos.core.auth.system.type=ldap，{0} is Placeholder,replace login username\n# nacos.core.auth.ldap.url=ldap://localhost:389\n# nacos.core.auth.ldap.userdn=cn={0},ou=user,dc=company,dc=com\n\n### The token expiration in seconds:\nnacos.core.auth.default.token.expire.seconds=18000\n\n### The default token:\nnacos.core.auth.default.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789\n\n### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.\nnacos.core.auth.caching.enabled=true\n\n### Since 1.4.1, Turn on/off white auth for user-agent: nacos-server, only for upgrade from old version.\nnacos.core.auth.enable.userAgentAuthWhite=false\n\n### Since 1.4.1, worked when nacos.core.auth.enabled=true and nacos.core.auth.enable.userAgentAuthWhite=false.\n### The two properties is the white list for auth and used by identity the request from other server.\nnacos.core.auth.server.identity.key=serverIdentity\nnacos.core.auth.server.identity.value=security\n\n#*************** Istio Related Configurations ***************#\n### If turn on the MCP server:\nnacos.istio.mcp.server.enabled=false\n\n#*************** Core Related Configurations ***************#\n\n### set the WorkerID manually\n# nacos.core.snowflake.worker-id=\n\n### Member-MetaData\n# nacos.core.member.meta.site=\n# nacos.core.member.meta.adweight=\n# nacos.core.member.meta.weight=\n\n### MemberLookup\n### Addressing pattern category, If set, the priority is highest\n# nacos.core.member.lookup.type=[file,address-server]\n## Set the cluster list with a configuration file or command-line argument\n# nacos.member.list=192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809\n## for AddressServerMemberLookup\n# Maximum number of retries to query the address server upon initialization\n# nacos.core.address-server.retry=5\n## Server domain name address of [address-server] mode\n# address.server.domain=jmenv.tbsite.net\n## Server port of [address-server] mode\n# address.server.port=8080\n## Request address of [address-server] mode\n# address.server.url=/nacos/serverlist\n\n#*************** JRaft Related Configurations ***************#\n\n### Sets the Raft cluster election timeout, default value is 5 second\n# nacos.core.protocol.raft.data.election_timeout_ms=5000\n### Sets the amount of time the Raft snapshot will execute periodically, default is 30 minute\n# nacos.core.protocol.raft.data.snapshot_interval_secs=30\n### raft internal worker threads\n# nacos.core.protocol.raft.data.core_thread_num=8\n### Number of threads required for raft business request processing\n# nacos.core.protocol.raft.data.cli_service_thread_num=4\n### raft linear read strategy. Safe linear reads are used by default, that is, the Leader tenure is confirmed by heartbeat\n# nacos.core.protocol.raft.data.read_index_type=ReadOnlySafe\n### rpc request timeout, default 5 seconds\n# nacos.core.protocol.raft.data.rpc_request_timeout_ms=5000\n\n#*************** Distro Related Configurations ***************#\n\n### Distro data sync delay time, when sync task delayed, task will be merged for same data key. Default 1 second.\n# nacos.core.protocol.distro.data.sync.delayMs=1000\n\n### Distro data sync timeout for one sync data, default 3 seconds.\n# nacos.core.protocol.distro.data.sync.timeoutMs=3000\n\n### Distro data sync retry delay time when sync data failed or timeout, same behavior with delayMs, default 3 seconds.\n# nacos.core.protocol.distro.data.sync.retryDelayMs=3000\n\n### Distro data verify interval time, verify synced data whether expired for a interval. Default 5 seconds.\n# nacos.core.protocol.distro.data.verify.intervalMs=5000\n\n### Distro data verify timeout for one verify, default 3 seconds.\n# nacos.core.protocol.distro.data.verify.timeoutMs=3000\n\n### Distro data load retry delay when load snapshot data failed, default 30 seconds.\n# nacos.core.protocol.distro.data.load.retryDelayMs=30000\n```\n\n### 启动 Docker 容器\n\n映射端口和路径，启动容器（我的是 win10 路径）\n\n```bash\ndocker run -p 8001:8080 -v D:\\docker\\volume\\regist_center\\:/usr/java/workpath --name register_center -d jar_runner:open-jre8\n```\n\n用上面命令创建容器后会生成 D:\\docker\\volume\\regist_center\\on_boot.sh 这个文件后退出，加入一行启动 nacos 的命令：\n\n```bash\n# 如果是集群部署，去掉后面的 -m standalone\n# 先 cd 到 nacos，不然会在 /usr/java/workpath 这一层就生成 tomcat 的日志文件\ncd /usr/java/workpath/nacos/ && bash ./bin/startup.sh -m standalone\n```\n\n然后再启动容器，会看到生成了 logs 文件夹，查看一下 nacos/logs/start.out，看有没有报错。\n第一次启动会生成各种文件，所需要的时间比较久。没有报错的话可以打开浏览器访问控制台 http://localhost:8001/nacos 用户名和密码都是 nacos\n\n### 服务注册客户端\n\n\n","BookId":"M-154268230","CompileTime":"2022-04-15T10:39:49.873Z"},{"FileTitle":"创建 docker jre8 镜像","BookName":"Java 笔记","Date":"2021-11-04","Description":"通过 Dockerfile 创建一个镜像，并设置一个启动脚本让容器启动时自动启动 jar 包，并且支持带参数的启动。","Keywords":"java,jre8,docker,Dockerfile","FilePath":"java/docker-jre8.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/docker-jre8.md","Content":null,"BookId":"M-154268230"},{"FileTitle":"Spring-Cloud 微服务各种概念","BookName":"Java 笔记","Date":"2019-11-21","Description":"spring cloud 微服务概念总结","Keywords":"java,spring cloud,概念","FilePath":"java/spring-cloud-ls.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/spring-cloud-ls.md","Content":null,"BookId":"M-154268230"},{"FileTitle":"Spring-Cloud 微服务学习日志 (Eureka)","BookName":"Java 笔记","Date":"2019-11-21","Description":"spring cloud 微服务配置与应用 (Eureka)","Keywords":"java,spring cloud,eureka","FilePath":"java/spring-cloud-eureka.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/spring-cloud-eureka.md","Content":null,"BookId":"M-154268230"},{"FileTitle":"“自适应”的 String 转 Date 工具","BookName":"Java 笔记","Date":"2018-11-09","Description":"预先注册可能用到的日期格式，之后可通过传入的字符串特征自动转换成 Date 对象，而不需要另外指定格式。","Keywords":"java,DateFormat","FilePath":"java/dateFormatter.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/java/dateFormatter.md","Content":null,"BookId":"M-154268230"}]},"P35186368":{"BookId":"P35186368","BookName":"课外题","contents":[{"FileTitle":"华硕路由器折腾日记","BookName":"课外题","Date":"2021-11-18","Description":"华硕路由器折腾日记：安装entware环境，开机自动执行脚本，安装下载工具、上网工具，微信通知，定时调度功能等。","Keywords":"asus router,华硕路由器","FilePath":"oth/asus_ac66ub1.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/oth/asus_ac66ub1.md","Content":"# 说明\n下面这些玩法基本上都是看教程做出来的。\n我在路由器上做成了以下事情：\n1. 安装 entware\n2. 微信通知，下载完成、开机完成、自动备份完成后进行微信通知\n3. aria2、v2\\*\\*y\n4. 开机自动挂载 entware 环境，自动启动一些程序，定时执行脚本\n\n注：本笔记涉及路由器型号为 RT-AC66U-B1，固件为官方固件，其他型号和固件理论上某些地方会有一些差别，甚至是不适用。\n挂载 /opt 的 U 盘使用 *ext3* 格式，NTFS 有段时间经常掉盘。\n需要先开启 ssh，然后用 putty 连接进入终端\n\n## 安装 entware\n\n```bash\n三个步骤\n1. 插入 U 盘，格式化成 ext3\n# 略\n2. 建立 /opt 软链接\nmkdir /mnt/sda1/.asus_opt\nln -s /mnt/sda1/.asus_opt /tmp/opt\n3. 执行安装脚本，这里需要先执行 uname -a 看下 cpu 是不是 armv7，不同 cpu 安装脚本应该不同\nwget http://pkg.entware.net/binaries/armv7/installer/entware_install.sh -O entware_install.sh\nchmod +x entware_install.sh\nsh entware_install.sh\n```\n\n执行后如果没报错就可以使用 opkg 了，看下支持哪些程序。 ```opkg list```\n\n## 使用微信通知\n这也是现成的，需要关注一个公众号。说明文档：https://github.com/wxpusher/wxpusher-docs\n\n```bash\n# 发送微信通知\n# 两个参数，第一个信息标题；第二个信息内容\n# 利用的轮子：https://github.com/wxpusher/wxpusher-docs\nout_wxmsg() #发送微信通知 $title $body\n{\n\thead=\"Content-Type:application/json\"\n\turl=\"http://wxpusher.zjiecode.com/api/send/message\"\n\t\n\tsummary=\"\"\n\tcontent=\"\"\n\ttitle=$1\n\tshift 1\n\tcontent=\"$title\\n\\n$@\"\n\tif [ ${#content} -gt 100 ]; then\n\t\tsummary=\"${content:0:95}\\n...\"\n\telse\n\t\tsummary=\"$content\"\n\tfi\n\n\t# 组装body\n\tbody=\"\"\n\tbody=\"$body{\"\n\tbody=\"$body\\\"appToken\\\":\\\"AT_**********pszcxd7J4u\\\",\"\n\tbody=\"$body\\\"content\\\":\\\"$content\\\",\"\n\tbody=\"$body\\\"summary\\\":\\\"$summary\\\",\\\"contentType\\\":1,\\\"uids\\\":[\\\"UID_HMzf********mey1THfq\\\"]\"\n\tbody=\"$body}\"\n\n\t#echo $body\n\t_log \"send wxmsg result: \" $(curl -H $head -d \"$body\" $url)\n}\n```\n\n## 安装各种软件\n\n### aria2\n这个可以直接用 opkg 里的，版本是 1.35.0 已经够用\n\n    opkg install arai2\n\n配置文件是用的 github 某个大哥的，我稍微改了下，主要是改路径，以及 on-download-complete.sh 加入下载完成后做微信通知。\n\n```\n#\n# Copyright (c) 2018-2020 P3TERX <https://p3terx.com>\n#\n# This is free software, licensed under the MIT License.\n# See /LICENSE for more information.\n#\n# https://github.com/P3TERX/aria2.conf\n# File name：aria2.conf\n# Description: Awesome Aria2 configuration file\n# Version: 2020.12.28\n#\n\n## 文件保存设置 ##\n\n# 下载目录。可使用绝对路径或相对路径, 默认: 当前启动位置\ndir=/media/Download\n\n# 磁盘缓存, 0 为禁用缓存，默认:16M\n# 磁盘缓存的作用是把下载的数据块临时存储在内存中，然后集中写入硬盘，以减少磁盘 I/O ，提升读写性能，延长硬盘寿命。\n# 建议在有足够的内存空闲情况下适当增加，但不要超过剩余可用内存空间大小。\n# 此项值仅决定上限，实际对内存的占用取决于网速(带宽)和设备性能等其它因素。\ndisk-cache=64M\n\n# 文件预分配方式, 可选：none, prealloc, trunc, falloc, 默认:prealloc\n# 预分配对于机械硬盘可有效降低磁盘碎片、提升磁盘读写性能、延长磁盘寿命。\n# 机械硬盘使用 ext4（具有扩展支持），btrfs，xfs 或 NTFS（仅 MinGW 编译版本）等文件系统建议设置为 falloc\n# 若无法下载，提示 fallocate failed.cause：Operation not supported 则说明不支持，请设置为 none\n# prealloc 分配速度慢, trunc 无实际作用，不推荐使用。\n# 固态硬盘不需要预分配，只建议设置为 none ，否则可能会导致双倍文件大小的数据写入，从而影响寿命。\nfile-allocation=none\n\n# 文件预分配大小限制。小于此选项值大小的文件不预分配空间，单位 K 或 M，默认：5M\nno-file-allocation-limit=64M\n\n# 断点续传\ncontinue=true\n\n# 始终尝试断点续传，无法断点续传则终止下载，默认：true\nalways-resume=false\n\n# 不支持断点续传的 URI 数值，当 always-resume=false 时生效。\n# 达到这个数值从将头开始下载，值为 0 时所有 URI 不支持断点续传时才从头开始下载。\nmax-resume-failure-tries=0\n\n# 获取服务器文件时间，默认:false\nremote-time=true\n\n\n## 进度保存设置 ##\n\n# 从会话文件中读取下载任务\ninput-file=/opt/workspace/aria2/aria2.session\n\n# 会话文件保存路径\n# Aria2 退出时或指定的时间间隔会保存`错误/未完成`的下载任务到会话文件\nsave-session=/opt/workspace/aria2/aria2.session\n\n# 任务状态改变后保存会话的间隔时间（秒）, 0 为仅在进程正常退出时保存, 默认:0\n# 为了及时保存任务状态、防止任务丢失，此项值只建议设置为 1\nsave-session-interval=1\n\n# 自动保存任务进度到控制文件(*.aria2)的间隔时间（秒），0 为仅在进程正常退出时保存，默认：60\n# 此项值也会间接影响从内存中把缓存的数据写入磁盘的频率\n# 想降低磁盘 IOPS (每秒读写次数)则提高间隔时间\n# 想在意外非正常退出时尽量保存更多的下载进度则降低间隔时间\n# 非正常退出：进程崩溃、系统崩溃、SIGKILL 信号、设备断电等\nauto-save-interval=20\n\n# 强制保存，即使任务已完成也保存信息到会话文件, 默认:false\n# 开启后会在任务完成后保留 .aria2 文件，文件被移除且任务存在的情况下重启后会重新下载。\n# 关闭后已完成的任务列表会在重启后清空。\nforce-save=true\n\n\n## 下载连接设置 ##\n\n# 文件未找到重试次数，默认:0 (禁用)\n# 重试时同时会记录重试次数，所以也需要设置 max-tries 这个选项\nmax-file-not-found=10\n\n# 最大尝试次数，0 表示无限，默认:5\nmax-tries=0\n\n# 重试等待时间（秒）, 默认:0 (禁用)\nretry-wait=10\n\n# 连接超时时间（秒）。默认：60\nconnect-timeout=30\n\n# 超时时间（秒）。默认：60\ntimeout=30\n\n# 最大同时下载任务数, 运行时可修改, 默认:5\nmax-concurrent-downloads=5\n\n# 单服务器最大连接线程数, 任务添加时可指定, 默认:1\n# 最大值为 16 (增强版无限制), 且受限于单任务最大连接线程数(split)所设定的值。\nmax-connection-per-server=16\n\n# 单任务最大连接线程数, 任务添加时可指定, 默认:5\nsplit=64\n\n# 文件最小分段大小, 添加时可指定, 取值范围 1M-1024M (增强版最小值为 1K), 默认:20M\n# 比如此项值为 10M, 当文件为 20MB 会分成两段并使用两个来源下载, 文件为 15MB 则只使用一个来源下载。\n# 理论上值越小使用下载分段就越多，所能获得的实际线程数就越大，下载速度就越快，但受限于所下载文件服务器的策略。\nmin-split-size=4M\n\n# HTTP/FTP 下载分片大小，所有分割都必须是此项值的倍数，最小值为 1M (增强版为 1K)，默认：1M\npiece-length=1M\n\n# 允许分片大小变化。默认：false\n# false：当分片大小与控制文件中的不同时将会中止下载\n# true：丢失部分下载进度继续下载\nallow-piece-length-change=true\n\n# 最低下载速度限制。当下载速度低于或等于此选项的值时关闭连接（增强版本为重连），此选项与 BT 下载无关。单位 K 或 M ，默认：0 (无限制)\nlowest-speed-limit=0\n\n# 全局最大下载速度限制, 运行时可修改, 默认：0 (无限制)\nmax-overall-download-limit=0\n\n# 单任务下载速度限制, 默认：0 (无限制)\nmax-download-limit=0\n\n# 禁用 IPv6, 默认:false\ndisable-ipv6=true\n\n# GZip 支持，默认:false\nhttp-accept-gzip=true\n\n# URI 复用，默认: true\nreuse-uri=false\n\n# 禁用 netrc 支持，默认:false\nno-netrc=true\n\n# 允许覆盖，当相关控制文件(.aria2)不存在时从头开始重新下载。默认:false\nallow-overwrite=false\n\n# 文件自动重命名，此选项仅在 HTTP(S)/FTP 下载中有效。新文件名在名称之后扩展名之前加上一个点和一个数字（1..9999）。默认:true\nauto-file-renaming=true\n\n# 使用 UTF-8 处理 Content-Disposition ，默认:false\ncontent-disposition-default-utf8=true\n\n# 最低 TLS 版本，可选：TLSv1.1、TLSv1.2、TLSv1.3 默认:TLSv1.2\n#min-tls-version=TLSv1.2\n\n\n## BT/PT 下载设置 ##\n\n# BT 监听端口(TCP), 默认:6881-6999\n# 直通外网的设备，比如 VPS ，务必配置防火墙和安全组策略允许此端口入站\n# 内网环境的设备，比如 NAS ，除了防火墙设置，还需在路由器设置外网端口转发到此端口\nlisten-port=51413\n\n# DHT 网络与 UDP tracker 监听端口(UDP), 默认:6881-6999\n# 因协议不同，可以与 BT 监听端口使用相同的端口，方便配置防火墙和端口转发策略。\ndht-listen-port=51413\n\n# 启用 IPv4 DHT 功能, PT 下载(私有种子)会自动禁用, 默认:true\nenable-dht=true\n\n# 启用 IPv6 DHT 功能, PT 下载(私有种子)会自动禁用，默认:false\n# 在没有 IPv6 支持的环境开启可能会导致 DHT 功能异常\nenable-dht6=false\n\n# 指定 BT 和 DHT 网络中的 IP 地址\n# 使用场景：在家庭宽带没有公网 IP 的情况下可以把 BT 和 DHT 监听端口转发至具有公网 IP 的服务器，在此填写服务器的 IP ，可以提升 BT 下载速率。\n#bt-external-ip=\n\n# IPv4 DHT 文件路径，默认：$HOME/.aria2/dht.dat\ndht-file-path=/opt/workspace/aria2/aria2.dht.dat\n\n# IPv6 DHT 文件路径，默认：$HOME/.aria2/dht6.dat\ndht-file-path6=/root/.aria2/dht6.dat\n\n# IPv4 DHT 网络引导节点\ndht-entry-point=dht.transmissionbt.com:6881\n\n# IPv6 DHT 网络引导节点\ndht-entry-point6=dht.transmissionbt.com:6881\n\n# 本地节点发现, PT 下载(私有种子)会自动禁用 默认:false\nbt-enable-lpd=true\n\n# 指定用于本地节点发现的接口，可能的值：接口，IP地址\n# 如果未指定此选项，则选择默认接口。\n#bt-lpd-interface=\n\n# 启用节点交换, PT 下载(私有种子)会自动禁用, 默认:true\nenable-peer-exchange=true\n\n# BT 下载最大连接数（单任务），运行时可修改。0 为不限制，默认:55\n# 理想情况下连接数越多下载越快，但在实际情况是只有少部分连接到的做种者上传速度快，其余的上传慢或者不上传。\n# 如果不限制，当下载非常热门的种子或任务数非常多时可能会因连接数过多导致进程崩溃或网络阻塞。\n# 进程崩溃：如果设备 CPU 性能一般，连接数过多导致 CPU 占用过高，因资源不足 Aria2 进程会强制被终结。\n# 网络阻塞：在内网环境下，即使下载没有占满带宽也会导致其它设备无法正常上网。因远古低性能路由器的转发性能瓶颈导致。\nbt-max-peers=128\n\n# BT 下载期望速度值（单任务），运行时可修改。单位 K 或 M 。默认:50K\n# BT 下载速度低于此选项值时会临时提高连接数来获得更快的下载速度，不过前提是有更多的做种者可供连接。\n# 实测临时提高连接数没有上限，但不会像不做限制一样无限增加，会根据算法进行合理的动态调节。\nbt-request-peer-speed-limit=10M\n\n# 全局最大上传速度限制, 运行时可修改, 默认:0 (无限制)\n# 设置过低可能影响 BT 下载速度\nmax-overall-upload-limit=2M\n\n# 单任务上传速度限制, 默认:0 (无限制)\nmax-upload-limit=0\n\n# 最小分享率。当种子的分享率达到此选项设置的值时停止做种, 0 为一直做种, 默认:1.0\n# 强烈建议您将此选项设置为大于等于 1.0\nseed-ratio=1.0\n\n# 最小做种时间（分钟）。设置为 0 时将在 BT 任务下载完成后停止做种。\nseed-time=0\n\n# 做种前检查文件哈希, 默认:true\nbt-hash-check-seed=true\n\n# 继续之前的BT任务时, 无需再次校验, 默认:false\nbt-seed-unverified=false\n\n# BT tracker 服务器连接超时时间（秒）。默认：60\n# 建立连接后，此选项无效，将使用 bt-tracker-timeout 选项的值\nbt-tracker-connect-timeout=10\n\n# BT tracker 服务器超时时间（秒）。默认：60\nbt-tracker-timeout=10\n\n# BT 服务器连接间隔时间（秒）。默认：0 (自动)\n#bt-tracker-interval=0\n\n# BT 下载优先下载文件开头或结尾\nbt-prioritize-piece=head=32M,tail=32M\n\n# 保存通过 WebUI(RPC) 上传的种子文件(.torrent)，默认:true\n# 所有涉及种子文件保存的选项都建议开启，不保存种子文件有任务丢失的风险。\n# 通过 RPC 自定义临时下载目录可能不会保存种子文件。\nrpc-save-upload-metadata=true\n\n# 下载种子文件(.torrent)自动开始下载, 默认:true，可选：false|mem\n# true：保存种子文件\n# false：仅下载种子文件\n# mem：将种子保存在内存中\nfollow-torrent=true\n\n# 种子文件下载完后暂停任务，默认：false\n# 在开启 follow-torrent 选项后下载种子文件或磁力会自动开始下载任务进行下载，而同时开启当此选项后会建立相关任务并暂停。\npause-metadata=false\n\n# 保存磁力链接元数据为种子文件(.torrent), 默认:false\nbt-save-metadata=true\n\n# 加载已保存的元数据文件(.torrent)，默认:false\nbt-load-saved-metadata=true\n\n# 删除 BT 下载任务中未选择文件，默认:false\nbt-remove-unselected-file=true\n\n# BT强制加密, 默认: false\n# 启用后将拒绝旧的 BT 握手协议并仅使用混淆握手及加密。可以解决部分运营商对 BT 下载的封锁，且有一定的防版权投诉与迅雷吸血效果。\n# 此选项相当于后面两个选项(bt-require-crypto=true, bt-min-crypto-level=arc4)的快捷开启方式，但不会修改这两个选项的值。\nbt-force-encryption=true\n\n# BT加密需求，默认：false\n# 启用后拒绝与旧的 BitTorrent 握手协议(\\19BitTorrent protocol)建立连接，始终使用混淆处理握手。\n#bt-require-crypto=true\n\n# BT最低加密等级，可选：plain（明文），arc4（加密），默认：plain\n#bt-min-crypto-level=arc4\n\n# 分离仅做种任务，默认：false\n# 从正在下载的任务中排除已经下载完成且正在做种的任务，并开始等待列表中的下一个任务。\nbt-detach-seed-only=true\n\n\n## 客户端伪装 ##\n\n# 自定义 User Agent\nuser-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Edg/87.0.664.57\n\n# BT 客户端伪装\n# PT 下载需要保持 user-agent 和 peer-agent 两个参数一致\n# 部分 PT 站对 Aria2 有特殊封禁机制，客户端伪装不一定有效，且有封禁账号的风险。\n#user-agent=Transmission 2.94\npeer-agent=Transmission 2.94\npeer-id-prefix=-TR2940-\n\n\n## 执行额外命令 ##\n\n# 下载停止后执行的命令\n# 从 正在下载 到 删除、错误、完成 时触发。暂停被标记为未开始下载，故与此项无关。\n#on-download-stop=/opt/workspace/aria2/on-download-error.sh\n\n# 下载完成后执行的命令\n# 此项未定义则执行 下载停止后执行的命令 (on-download-stop)\non-download-complete=/opt/workspace/aria2/on-download-complete.sh\n\n# 下载错误后执行的命令\n# 此项未定义则执行 下载停止后执行的命令 (on-download-stop)\non-download-error=/opt/workspace/aria2/on-download-error.sh\n\n# 下载暂停后执行的命令\n#on-download-pause=\n\n# 下载开始后执行的命令\n#on-download-start=\n\n## RPC 设置 ##\n\n# 启用 JSON-RPC/XML-RPC 服务器, 默认:false\nenable-rpc=true\n\n# 接受所有远程请求, 默认:false\nrpc-allow-origin-all=true\n\n# 允许外部访问, 默认:false\nrpc-listen-all=true\n\n# RPC 监听端口, 默认:6800\nrpc-listen-port=6900\n\n# RPC 密钥\nrpc-secret=simple-rpc-001\n\n# RPC 最大请求大小\nrpc-max-request-size=10M\n\n# RPC 服务 SSL/TLS 加密, 默认：false\n# 启用加密后必须使用 https 或者 wss 协议连接\n# 不推荐开启，建议使用 web server 反向代理，比如 Nginx、Caddy ，灵活性更强。\n#rpc-secure=false\n\n# 在 RPC 服务中启用 SSL/TLS 加密时的证书文件(.pem/.crt)\n#rpc-certificate=/root/.aria2/xxx.pem\n\n# 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件(.key)\n#rpc-private-key=/root/.aria2/xxx.key\n\n# 事件轮询方式, 可选：epoll, kqueue, port, poll, select, 不同系统默认值不同\n#event-poll=select\n\n\n## 高级选项 ##\n\n# 启用异步 DNS 功能。默认：true\n#async-dns=true\n\n# 指定异步 DNS 服务器列表，未指定则从 /etc/resolv.conf 中读取。\n#async-dns-server=119.29.29.29,223.5.5.5,8.8.8.8,1.1.1.1\n\n# 指定单个网络接口，可能的值：接口，IP地址，主机名\n# 如果接口具有多个 IP 地址，则建议指定 IP 地址。\n# 已知指定网络接口会影响依赖本地 RPC 的连接的功能场景，即通过 localhost 和 127.0.0.1 无法与 Aria2 服务端进行讯通。\n#interface=\n\n# 指定多个网络接口，多个值之间使用逗号(,)分隔。\n# 使用 interface 选项时会忽略此项。\n#multiple-interface=\n\n\n## 日志设置 ##\n\n# 日志文件保存路径，忽略或设置为空为不保存，默认：不保存\n#log=/opt/workspace/aria2/aria2.log\n\n# 日志级别，可选 debug, info, notice, warn, error 。默认：debug\n#log-level=warn\n\n# 控制台日志级别，可选 debug, info, notice, warn, error ，默认：notice\nconsole-log-level=notice\n\n# 安静模式，禁止在控制台输出日志，默认：false\nquiet=true\n\n# 下载进度摘要输出间隔时间（秒），0 为禁止输出。默认：60\nsummary-interval=0\n\n\n## 增强扩展设置(非官方) ##\n\n# 仅适用于 myfreeer/aria2-build-msys2 (Windows) 和 P3TERX/Aria2-Pro-Core (GNU/Linux) 项目所构建的增强版本\n\n# 在服务器返回 HTTP 400 Bad Request 时重试，仅当 retry-wait > 0 时有效，默认 false\n#retry-on-400=true\n\n# 在服务器返回 HTTP 403 Forbidden 时重试，仅当 retry-wait > 0 时有效，默认 false\n#retry-on-403=true\n\n# 在服务器返回 HTTP 406 Not Acceptable 时重试，仅当 retry-wait > 0 时有效，默认 false\n#retry-on-406=true\n\n# 在服务器返回未知状态码时重试，仅当 retry-wait > 0 时有效，默认 false\n#retry-on-unknown=true\n\n# 是否发送 Want-Digest HTTP 标头。默认：false (不发送)\n# 部分网站会把此标头作为特征来检测和屏蔽 Aria2\n#http-want-digest=false\n\n\n## BitTorrent trackers ##\nbt-tracker=\n```\n\n下载完后或下载失败后的微信通知，on-download-complete.sh 内容如下：\n\n```bash\n#!/bin/bash\nif [[ \"$2\" == \"0\" ]]; then\n\texit 0\nfi\n\nfilePath=$3\nbody=\"文件数：$2\\n文件路径：${filePath%/*}\"\nsh /jffs/script/main.sh wxmsg \"aria2下载成功\" \"$body\"\n```\n\n### 安装 v2\\*\\*y\n我服务器是自己搭建的 tr\\*\\*jan 协议，但客户端还是比较喜欢这个，比较万能。\n    ```opkg list | grep v2\\*\\*y```  发现以及有这个包了，这个路由器不支持硬浮点，所以肯定是安装 v2\\*\\*y_nohf 这个。但我一番操作以后发现貌似跑不起来，所以还是自己编译一个比较好。\n在路由器上可以编译的，```opkg install go_nohf``` 需要下载这个 go。关于怎么编译这个东西不能说多，github 上有教程。我也编写了一个编译的脚本，用现在的源码编译出来是4.31.0 编译的过程中有两处报错，只需要在源码中删掉报错的行就行（手动狗头）。\n有意思的是源码是需要外网才能下载下来，如果只用路由器几乎无解。我的办法是先在win10客户端上设置“允许局域网内链接访问”，让路由器走电脑的代理，成功 get 到源码。\n另外透明代理我没研究，对于我而言，我只需要 ipad 能看 youtobe，设置一个 http 的代理足够，在 wifi 设置那里可以设置代理。\n编译脚本：\n\n```bash\n\n#!/bin/bash\n\nSHELL_FOLDER=$(cd \"$(dirname \"$0\")\";pwd)\nexport GOROOT=/opt/bin/go\nexport GOPATH=\"$SHELL_FOLDER/GOPATH\"\nexport GOCACHE=\"$SHELL_FOLDER/GOCACHE\"\nexport GOINSECURE=v2\\*\\*y.com\nexport GOPROXY=https://goproxy.io\nexport GO111MODULE=off\nexport CGO_ENABLED=0\n# 下面两个代理地址换成电脑的ip\nexport http_proxy=http://127.0.0.1:10809\nexport https_proxy=http://127.0.0.1:10809\n\ncd $SHELL_FOLDER\necho \"rm -r GOPATH & GOCACHE\"\n# rm -r ./GOPATH\n# rm -r ./GOCACHE\n\necho \"GOROOT: $GOROOT\"\n\nls -alch\n\nmkdir GOPATH\nmkdir GOCACHE\n\necho \"cmd: go get -u v2\\*\\*y.com/core/...\"\ngo get -u v2\\*\\*y.com/core/...\n\necho \"cmd: go get -u v2\\*\\*y.com/ext/...\"\ngo get -u v2\\*\\*y.com/ext/...\n\n### 下面试编译，如果报错了，需要删掉出错的代码行再执行一遍\n\necho \"rm v2\\*\\*y & v2ctl\"\nrm ./v2\\*\\*y\nrm ./v2\\*\\*l\n\necho \"GOROOT: $GOROOT\"\n\nls -alch\n\ncd $GOPATH/src/v2\\*\\*y.com/core/main\necho \"cmd: go build -o $SHELL_FOLDER/v2\\*\\*y -ldflags \\\"-s -w\\\"\"\ngo build -o $SHELL_FOLDER/v2\\*\\*y -ldflags \"-s -w\"\n\ncd $GOPATH/src/v2\\*\\*y.com/core/infra/control/main\necho \"cmd: go build -o $SHELL_FOLDER/v2ctl -tags confonly -ldflags \\\"-s -w\\\"\"\ngo build -o $SHELL_FOLDER/v2\\*\\*l -tags confonly -ldflags \"-s -w\"\n\necho \"done\"\n```\n\n### 安装 nginx\n需要 nginx 提供 pac.js\n\n```opkg install nginx```\n\n主要是路由器自动申请的证书路径需要注意下（不过443端口一般都封了，证书没什么实际意义）\n配置文件路径在 /opt/etc/nginx/nginx.conf，参考配置：\n\n```\n\nuser nobody;\nworker_processes  1;\n\n#error_log  /opt/var/log/nginx/error.log;\n#error_log  /opt/var/log/nginx/error.log  notice;\n#error_log  /opt/var/log/nginx/error.log  info;\n\n#pid        /opt/var/run/nginx.pid;\n\nevents {\n    worker_connections  64;\n}\n\nhttp {\n    include            mime.types;\n    default_type       application/octet-stream;\n    sendfile           on;\n    keepalive_timeout  65;\n    #gzip  on;\n\n    # HTTPS server\n    server {\n        listen       443 ;\n        charset      utf-8;\n        server_name  yourname.asuscomm.com;\n        \n        #auth_basic           \"Restricted\";\n        #auth_basic_user_file /opt/workspace/nginx/passwd;\n\n\t\t# 路由器自动申请的证书位置\n        ssl_certificate      /etc/cert.pem;\n        ssl_certificate_key  /etc/key.pem;\n\n        #ssl_session_cache    shared:SSL:1m;\n        #ssl_session_timeout  5m;\n\n        #ssl_ciphers  HIGH:!aNULL:!MD5;\n        #ssl_prefer_server_ciphers  on;\n\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n        location /maven_repo/ {\n            root                  /opt/workspace/maven/;\n            autoindex_exact_size  on;\n            autoindex             on;\n            autoindex_localtime   on;\n            auth_basic            \"Restricted\";\n            auth_basic_user_file  /opt/workspace/nginx/passwd;\n        }\n    }\n    server {\n        listen       483 ;\n        charset      utf-8;\n        server_name  atcn.asuscomm.com;\n        \n        #auth_basic           \"Restricted\";\n        #auth_basic_user_file /opt/workspace/nginx/passwd;\n\n        #ssl_certificate      /etc/cert.pem;\n        #ssl_certificate_key  /etc/key.pem;\n\n        #ssl_session_cache    shared:SSL:1m;\n        #ssl_session_timeout  5m;\n\n        #ssl_ciphers  HIGH:!aNULL:!MD5;\n        #ssl_prefer_server_ciphers  on;\n\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n        location /maven_repo/ {\n            alias                  /opt/workspace/maven/;\n            autoindex_exact_size  on;\n            autoindex             on;\n            autoindex_localtime   on;\n            auth_basic            \"Restricted\";\n\t\t\t# 这个路径需要用户名+密码验证权限\n            auth_basic_user_file  /opt/workspace/nginx/passwd;\n        }\n        location /notepad/ {\n            alias  /opt/workspace/web_notepad/client/;\n\t\t\tindex  index.html;\n        }\n        location /notepad_api/ {\n\t\t\t# 转发携带请求者真实 ip\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:8080/;\n        }\n    }\n}\n```\n\n### 安装 mysql\n\n 1 先安装，执行 ```opkg install mariadb-server``` 版本是最新的。\n 2 开启 512M swap。否则无法正常运行\n 3 修改配置文件，主要是记得改运行的用户名。参考配置：/opt/etc/mysql/conf.d/50-server.cnf\n\n```\n[server]\n# this is only for the mysqld standalone daemon\n[mysqld]\n# 设置完用户后注释掉再重启\nskip-grant-tables\n#\n# * Basic Settings\n#\nuser\t\t= admin\npid-file\t= /opt/var/run/mysqld/mysqld.pid\nsocket\t\t= /opt/var/run/mysqld/mysqld.sock\nport\t\t= 3306\nbasedir\t\t= /opt\n# mysql_install_db --force\ndatadir\t\t= /opt/workspace/mysql/datadir\n# tmpdir should also not go on flash memory\ntmpdir\t\t= /opt/tmp\nlc-messages-dir\t= /opt/share/mariadb\n\nskip-external-locking\n\nbind-address\t= 0.0.0.0\n\nkey_buffer_size\t\t= 16M\nmax_allowed_packet\t= 16M\nthread_stack\t\t= 192K\nthread_cache_size\t= 8\n\nmyisam_recover_options\t= BACKUP\n\nquery_cache_limit\t= 1M\nquery_cache_size\t= 16M\n\nexpire_logs_days\t= 10\nmax_binlog_size\t\t= 100M\n\ncharacter-set-server  = utf8mb4\ncollation-server      = utf8mb4_general_ci\n\n```\n\n 4 启动，这时候可以用 sqlYog 连接，不用用户和密码。然后用 sqlYog 设置好用户和密码，再注释掉配置文件里 skip-grant-tables 这一行。重启 mysql 后可以正常使用了。\n\n## 设置自动挂载 entware，以及自动执行一些脚本\n机器重启后发现输入 opkg 没反应了，原来是 /opt 软链没有自动挂载上去。\n一番搜索终于发现解决方法，可以通过以下命令设置 usb 挂载时自动执行一个 .sh 脚本，将 /opt 链上去。\n\n```bash\nnvram set script_usbmount=\"sh /jffs/etc/script_usbmount.sh\"\nnvram commit\n```\n\n以下两处网站都有提及这个方法\nhttps://www.52asus.com/thread-5934-1-1.html\nhttp://www.giuseppeparrello.it/en/net_router_install_entware.php\n\n其中 script_usbmount.sh 内容如下：\n\n```bash\n#!/bin/sh\n\n# 路由器可以插两个 U 盘，其中一个 U 盘根路径下有 .asus_opt 文件夹，将这个文件夹链接到 /opt\n# 没有 .asus_opt 文件夹的 U 盘作为存储盘，链接到 /media \nmnt_opt=`ls -d /tmp/mnt/*/.asus_opt | head -n 1`\nopt_disk=`dirname $mnt_opt`\nmnt_media=`ls -d /tmp/mnt/* | grep -v $opt_disk`\n\nif [[ ! -r \"/tmp/opt\" ]] && [[ $mnt_opt ]]; then\n\trm /tmp/opt\n\tln -s $mnt_opt /tmp/opt\n\tsh /jffs/script/main.sh event mount_opt\nfi\n\nif [[ ! -r \"/tmp/media\" ]] && [[ $mnt_media ]]; then\n\trm /tmp/media\n\tln -s $mnt_media /tmp/media\n\tsh /jffs/script/main.sh event mount_media\nfi\n```\n\nscript_usbmount.sh 是一个引导脚本，它在 U 盘挂载时执行，\n/jffs/script/main.sh 也是自己编写，接收 mount_opt、mount_media 两个事件并做分发，最终会通过事件名调用到 /jffs/script/mount_opt.sh、 /jffs/script/mount_media.sh 这两个脚本。\n\n/jffs/script/main.sh: \n\n```bash\n#!/bin/sh\nonlyImportFunctoin=\"No\"\nif [ \"${1}\" = \"--source-only\" ]; then\n    onlyImportFunctoin=\"Yes\"\nfi\n\n#################################### 内部方法 ####################################\n_getpid()\n{\n\techo `ps | grep $1 | grep -v grep | awk '{ print $1 }'`\n}\n_log()\n{\n\techo \"$(printf '[%5d]-' $)[$(TZ=UTC-8 date '+%Y-%m-%d %H:%M:%S')]: $@\"\n}\n# 利用文件锁，让程序同一时间只有一个在运行\nlockit()\n{\n\texec 7<>/jffs/utils.sh.lock\n\tflock -n 7 || {\n\t\t_log \"Waiting... \"\n\t\tflock 7\n\t}\n}\n\n#################################### 外部方法 ####################################\n\nout_stop() #停止一个程序，$proName\n{\n\tpname=$1\n\tpid=$(_getpid $pname)\n\tif [ -n \"$pid\" ]\n\tthen\n\t\t_log \"$pname pid: $pid\"\n\t\tkill $pid\n\t\twhile(true)\n\t\tdo\n\t\t\tsleep 1s\n\t\t\tpid=$(_getpid $pname)\n\t\t\tif [ -n \"$pid\" ]\n\t\t\tthen\n\t\t\t\t_log stopping\n\t\t\telse\n\t\t\t\t_log stopped\n\t\t\t\tbreak\n\t\t\tfi\n\t\tdone\n\telse\n\t\t_log \"$pname not running.\"\n\tfi\n}\n\nout_testspeed() #网络测速\n{\n\tspeedtest --no-pre-allocate\n}\n\n# 发送微信通知\n# 两个参数，第一个信息标题；第二个信息内容\n# 利用的轮子：https://github.com/wxpusher/wxpusher-docs\nout_wxmsg() #发送微信通知 $title $body\n{\n\thead=\"Content-Type:application/json\"\n\turl=\"http://wxpusher.zjiecode.com/api/send/message\"\n\t\n\tsummary=\"\"\n\tcontent=\"\"\n\ttitle=$1\n\tshift 1\n\tcontent=\"$title\\n\\n$@\"\n\tif [ ${#content} -gt 100 ]; then\n\t\tsummary=\"${content:0:95}\\n...\"\n\telse\n\t\tsummary=\"$content\"\n\tfi\n\n\t# 组装body\n\tbody=\"\"\n\tbody=\"$body{\"\n\tbody=\"$body\\\"appToken\\\":\\\"AT_z1u7i3kRWhylO3c6Mt067fpszcxd7J4u\\\",\"\n\tbody=\"$body\\\"content\\\":\\\"$content\\\",\"\n\tbody=\"$body\\\"summary\\\":\\\"$summary\\\",\\\"contentType\\\":1,\\\"uids\\\":[\\\"UID_HMzf36I7ZmiqWsy7QDlqmey1THfq\\\"]\"\n\tbody=\"$body}\"\n\n\t#echo $body\n\t_log \"send wxmsg result: \" $(curl -H $head -d \"$body\" $url)\n}\n\nout_openport() #在防火墙上打开一个端口，允许流量入站\n{\n\t_log \"open port: $1\"\n\t_exists=`iptables -nL INPUT | grep \"tcp dpt:$1\\$\"`\n\tif [ -n \"$_exists\" ]; then\n\t\t_log \"it's already opened.\"\n\telse\t\n\t\tiptables -I INPUT -i eth0 -p tcp --dport $1 -j ACCEPT\n\t\tiptables -I OUTPUT -o eth0 -p tcp --sport $1 -j ACCEPT\n\tfi\n#\t查看打开的端口\n#\tiptables -nL INPUT --line-number | grep \"tcp dpt:10809$\"\n#\t删除指定行\n#\tiptables -D INPUT 2\n}\n\nout_hosts_fresh() #强制刷新 hosts\n{\n\t_log hosts init start\n\techo \"# inited\" > /etc/hosts\n\techo \"192.168.50.1 RT-AC66U_B1-4D98\" >> /etc/hosts\n\techo \"127.0.0.1 x.x\" >> /etc/hosts\n\techo \"127.0.0.1 flnet.com\" >> /etc/hosts\n\techo \"127.0.0.1 miaozhen.com\" >> /etc/hosts\n#\techo \"192.168.50.1 atcn.asuscomm.com\" >> /etc/hosts\n\techo \"151.101.4.133 raw.githubusercontent.com\" >> /etc/hosts\n\tkillall -SIGHUP dnsmasq\n\tcurl https://raw.githubusercontent.com/vokins/yhosts/master/hosts >> /etc/hosts\n\tkillall -SIGHUP dnsmasq\n\tout_openport 483\n\tout_openport 10809\n\t_log hosts init done\n}\n\nout_hosts_init() #判断有没有刷新过 hosts，没有刷新过则进行刷新\n{\t\n\tline=$(head -n 1 /etc/hosts)\n\t_log hosts first line is $line\n\tif [[ \"$line\" == \"# inited\" ]]; then\n\t\t_log hosts inited, ignore\n\telse\n\t\tout_hosts_fresh\n\tfi\n}\n\nout_aria2_fresh() #刷新 aria2 的参数，包括 tracker 和对外 ip\n{\n\tpid=$(_getpid aria2c)\n\tif [ -n \"$pid\" ]\n\tthen\n\t\tout_openport 51413\n\t\tout_openport 6900\n\t\tpath='http://127.0.0.1:6900/jsonrpc'\n\t\tpasswd='simple-rpc-001'\n\t\t_log tracker init start\n\t\ttracker_url='https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all.txt'\n\t\ttracker=$(echo -n  $(curl -s -L $tracker_url | sed 'N;s/\\n//g') | tr ' ' ',')\n\t\tif [ -n \"$tracker\" ]; then\n\t\t\tres=$(echo -n $(curl $path -d '{\"jsonrpc\":\"2.0\",\"method\":\"aria2.changeGlobalOption\",\"id\":\"utils\",\"params\":[\"token:'$passwd'\",{\"bt-tracker\":\"'$tracker'\"}]}'))\n\t\t\t_log $res\n\t\tfi\n\t\t_log tracker init done.\n\t\t_log out_ip init start\n\t\tPUBLIC_IP=`wget -O - --no-check-certificate --quiet https://checkip.amazonaws.com/`\n\t\t_log set out_ip: $PUBLIC_IP\n\t\tres=$(echo -n $(curl $path -d '{\"jsonrpc\":\"2.0\",\"method\":\"aria2.changeGlobalOption\",\"id\":\"utils\",\"params\":[\"token:'$passwd'\",{\"bt-external-ip\":\"'$PUBLIC_IP'\"}]}'))\n\t\t_log out_ip init done.\n\telse\n\t\t_log aria2 not running.\n\tfi\n}\n\nout_aria2_start() #启动 aria2\n{\n\tout_openport 6900\n\taria2c --conf-path=/opt/workspace/aria2/aria2.conf -D\n\tout_aria2_fresh\n}\n\nout_aria2_stop() #停止 aria2\n{\n\tout_stop \"aria2c\"\n}\n\nout_svn_start() #启动 svn\n{\n\tout_openport 3690\n\tpid=$(_getpid svnserve)\n\tif [ -n \"$pid\" ]\n\tthen\n\t\t_log svnserve is already started.\n\telse\n\t\t_log svn startting...\n\t\tsvnserve -d -r /opt/svn\n\tfi\n}\n\nout_mysql_start() #启动 mysql\n{\n\tout_openport 3306\n\t_log \"startmysql: do start\"\n\tsh /opt/etc/init.d/S70mysqld start\n\tsleep 3s\n\t_log \"startmysql: check status.\"\n\tsh /opt/etc/init.d/S70mysqld status\n}\n\nout_mysql_stop() #停止 mysql\n{\n\tsh /opt/etc/init.d/S70mysqld stop\n\tsleep 3s\n\t_log \"startmysql: check status.\"\n\tsh /opt/etc/init.d/S70mysqld status\n}\n\nout_nginx_start() #启动 nginx\n{\n\tout_openport 483\n\tcp -au /opt/workspace/nginx/nginx.conf /opt/etc/nginx/\n\tsh /opt/etc/init.d/S80nginx start\n}\n\nout_nginx_stop() #停止 nginx\n{\n\tsh /opt/etc/init.d/S80nginx stop\n}\n\nout_swap_on() #开启 swap\n{\n\tSWAP_FILE=/opt/.swap\n\tif [[ ! -r \"/tmp/opt\" ]]; then\n\t\t_log /opt not mount.\n\telif [[ ! -r $SWAP_FILE ]]; then\n\t\t_log make swap file.\n\t\tdd if=/dev/zero of=$SWAP_FILE bs=1M count=512\n\t\tmkswap $SWAP_FILE\n\tfi\n\tswapon $SWAP_FILE\n\tfree -h\n}\n\nout_swap_off() #关闭 swap\n{\n\tswapoff -a\n\tfree -h\n}\n\n_backup()\n{\n\t_log \"backup: $1\"\n\tmkdir -p \"$2\"\n\tcp -au \"$1\" \"$2\"\n\t_log \"done.\"\n}\n\n# 备份，会备份到 /tmp/mnt/*/.asus_bak（任意一个 USB 根路径有 .asus_bak 则进行备份，否则不备份）\nout_backup() #本地备份\n{\n#\tgit -C /opt/workspace/code_clone/gitee/swpay_cloud/ pull origin master\n\tback_path=`ls -d /tmp/mnt/*/.asus_bak | head -n 1`\n\t_log \"backup to: $back_path\"\n\tif [[ ! -w \"$back_path\" ]]; then\n\t\t_log \"cant write: $back_path\"\n\t\treturn 0\n\tfi\n\t_backup \"/tmp/opt/git\" \"$back_path/opt/\"\n\t_backup \"/tmp/opt/svn\" \"$back_path/opt/\"\n\t_backup \"/tmp/opt/html\" \"$back_path/opt/\"\n\t_backup \"/tmp/opt/workspace\" \"$back_path/opt/\"\n\t_backup \"/jffs/etc\" \"$back_path/jffs/\"\n}\n\nout_v2\\*\\*y_start() #开启 v2\\*\\*y\n{\n\tout_openport 10808\n\tout_openport 10809\n\t`nohup /opt/workspace/v2\\*\\*y/v2\\*\\*y --config /opt/workspace/v2\\*\\*y/config.json >> /opt/workspace/v2\\*\\*y/nohup.log & exit`\n#\tcurl -x socks5://127.0.0.1:10808 google.com\n}\n\nout_status() #查询各个服务的运行状态\n{\n\tuptime\n\t_log hosts first line is $(head -n 1 /etc/hosts)\n\t_log aria2c pid $(_getpid aria2c)\n\t_log svnserve pid $(_getpid svnserve)\n\t_log nginx pid $(_getpid nginx)\n\t_log v2\\*\\*y pid $(_getpid v2\\*\\*y)\n\t_log trojan $(_getpid trojan)\n\t_log minidlna pid $(_getpid minidlna)\n\t_log mysql: $(sh /opt/etc/init.d/S70mysqld status)\n\t_log $(cat /proc/dmu/temperature)\n#\t_log OUT_IP: `wget -O - --no-check-certificate --quiet https://checkip.amazonaws.com/`\n}\n\n#################################### 事件触发 ####################################\n_callscripts()\n{\n\tcount=`ls $1*.sh 2>/dev/null| wc -w`\n\tif [ $count -gt 0 ]; then\n\t\tscripts=$(ls $1*.sh)\n\t\tfor script in ${scripts}; do\n\t\t\t_log \"call: $script\"\n\t\t\tsh ${script} $2 $3\n\t\tdone\n\tfi\n}\n# 触发事件，运行事件下面的脚本\nout_event()\n{\n\t# 获取脚本运行目录\n\tworkpath=$(dirname $(readlink -f \"$0\"))\n\t# nvram set script_usbmount=\"sh /jffs/etc/script_usbmount.sh\"\n\t# nvram commit\n\thn=\"\"\n\tif [[ \"$1\" == \"10m_in_hour\" ]]; then\n\t\thn=\"minute_$(TZ=UTC-8 date '+%M')\"\n\telif [[ \"$1\" == \"hour_in_date\" ]]; then\n\t\thn=\"hour_$(TZ=UTC-8 date '+%H')\"\n\telif [[ \"$1\" == \"day_in_week\" ]]; then\n\t\thn=\"day_$(TZ=UTC-8 date '+%w')\"\n\telif [[ \"$1\" == \"date_in_month\" ]]; then\n\t\thn=\"date_$(TZ=UTC-8 date '+%d')\"\n\telse\n\t\thn=\"$1\"\n\tfi\n\techo $(_log \"event start: $hn\") >> ${workpath}/.logs/event.log\n\t_callscripts \"$workpath/$hn\" \"${workpath}/main.sh\" \"${workpath}/.logs\" >> ${workpath}/.logs/event.log\n\techo $(_log \"event  done\") >> ${workpath}/.logs/event.log\n}\n\n# 程序主体罗辑部分\nif [ \"${onlyImportFunctoin}\" = \"Yes\" ]; then\n    return 0\nfi\nfname=\"\"\nif [ \"$(type -t out_$1_$2)\" ]; then\n\tfname=out_$1_$2\n\tshift 2\nelif [ \"$(type -t out_$1)\" ]; then\n\tfname=out_$1\n\tshift 1\nelse \n\t_log \"nothing todo, function list:\"\n\t# 打印出上面写的所有对外功能\n\tgrep \"^out_.*$\" $0 | sed 's/[_)(]/ /g' | awk '{print \"\\t\" $2\" \"$3\" \"$4 $5 $6 $7 $8 $9}'\n\texit 0\nfi\n\n_log ------------------- start with function [${fname:4}] -------------------\n#lockit\n$fname $@\n#rm /jffs/utils.sh.lock\n_log ------------------- \" end \" with function [${fname:4}] -------------------\n```\n\n/jffs/script/mount_opt.sh:\n\n```bash\n#!/bin/sh\n# 这里引入 main.sh 里面写好的函数，下面 _log 与 out_ 开头的函数都是在 main.sh 中定义好的\n# $1 即 main.sh 的绝对路径，由外部程序传入\n. $1 --source-only\nsct=$1\n\n_log \"mount opt\"\n# 注册域名 ip：开机时 ip 可能会变，重新注册一下\n_log \"regist public ip\"\nPUBLIC_IP=`wget -O - --no-check-certificate --quiet https://checkip.amazonaws.com/`\n/usr/sbin/ez-ipupdate -S dyndns -i eth0 -a $PUBLIC_IP -h yourname.asuscomm.com -A 2 -s nwsrv-ns1.asus.com\n# 加上 swap\n_log \"mount swap\"\nout_swap_on\n_log \"start service list\"\nout_v2**y_start\nout_nginx_start\nout_aria2_start\n_log \"do initlize task\"\n# 刷新 hosts\nout_hosts_init\nout_mysql_start\n# 启动定时任务\n# cru a {id} min hour day month week command\n## 在小时内，十分钟一次的调度\ncru a event_10m_in_hour  \"*/10 * * * * sh $sct event 10m_in_hour\"\n## 在一天内，每小时一次的调度\ncru a event_hour_in_date  \"0 * * * * sh $sct event hour_in_date\"\n## 在一周内，每天一次的调度\ncru a event_day_in_week  \"0 10 * * * sh $sct event day_in_week\"\n## 在一个月内，每天一次的调度\ncru a event_date_in_month \"0 10 * * * sh $sct event date_in_month\"\n# 发消息\nout_wxmsg \"服务启动成功\" \"启动时间：$(TZ=UTC-8 date '+%Y-%m-%d %H:%M:%S')\\n服务器IP：$PUBLIC_IP\"\n```\n\n每月 16 日截一下日志\n/jffs/script/date_16.sh:\n\n```bash\n#!/bin/sh\n. $1 --source-only\n\n_log \"###### cut logs\"\n# 清理日志\nlogs=$(ls $2/*.log)\nfor log in ${logs}; do\n\t_log \"cut log ${log}\"\n\ttail -100 ${log} > ${log}.temp\n\ttail -100 ${log}.temp > ${log}\n\trm ${log}.temp\ndone\n```\n\n// TODO 今天先记好流水账，改天有情绪了再整理。","BookId":"P35186368","CompileTime":"2022-04-15T10:39:49.761Z"},{"FileTitle":"demo","BookName":"课外题","Date":"2019-12-19","Description":"一个博文的demo","Keywords":"demo,markdown","FilePath":"demo.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/demo.md","Content":null,"BookId":"P35186368"},{"FileTitle":"magnet 魔链增加 tracker","Date":"2019-10-08","Description":"magnet 魔链增加 tracker，更新服务器信息，获取更快的下载速度","Keywords":"magnet,tracker","FilePath":"/page/magnet/mag.html","BookId":"P35186368","BookName":"课外题","FromSrc":true},{"FileTitle":"图片转字符画","Date":"2019-10-08","Description":"图片转字符画","Keywords":"图片,字符画","FilePath":"/page/pic/pic.html","BookId":"P35186368","BookName":"课外题","FromSrc":true},{"FileTitle":"图灵机器人试用","Date":"2015-10-12","Description":"调用图灵机器人的api实现自动聊天","Keywords":"图灵机器人","FilePath":"/page/wx_yuki/wx.html","BookId":"P35186368","BookName":"课外题","FromSrc":true}]},"P665848904":{"BookId":"P665848904","BookName":"Web & Node","contents":[{"FileTitle":"Js 简单实现类与继承","BookName":"Web & Node","Date":"2019-05-27","Description":"JS 简单实现类与继承","Keywords":"js,class","FilePath":"web/js_class.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/web/js_class.md","Content":null,"BookId":"P665848904"},{"FileTitle":"NodeJs 简单实现“模板文件”","BookName":"Web & Node","Date":"2018-03-07","Description":"简单的字符串模板实现","Keywords":"node,template","FilePath":"web/nodejs_template.md","PostPath":"/tmp/mnt/sda/.asus_opt/workspace/github/posts/web/nodejs_template.md","Content":null,"BookId":"P665848904"}]}}');
	initBookShelf(bookInfos);
</script>
<script src="/3rd-lib/markedjs/marked.js"></script>
<script src="/3rd-lib/prism/prism.js"></script>
<script data-runat="init">
	// 初始化文本
	var mdContent = $("noscript")[0].innerText;
	var currentInfo = {src: "java/spring-cloud-nacos.md", title: "Spring-Cloud nacos 学习笔记", date: "2021-11-10", keywords: "java,spring cloud,nacos", desc: "spring cloud nacos 学习笔记", id: stringToHashKey("java/spring-cloud-nacos.md")};
	if (mdContent.length) {
		setTimeout(() => {showPost(currentInfo, mdContent)}, 200);
	} else {
		currentInfo.src = "index.html";
		currentInfo.title = "首页";
		currentInfo.desc = "这里是首页";
		initTalk(currentInfo);
	}
</script>
</html>